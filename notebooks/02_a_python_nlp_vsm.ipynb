{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 02_a. Distributional word representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* 싸이그래머 / 어바웃 파이썬\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 차례\n",
    "* TF-IDF\n",
    "    - gensim으로 tf-idf\n",
    "    - scikit-learn으로 tf-idf\n",
    "* Distributional word representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TF-IDF\n",
    "* gensim으로 tf-idf\n",
    "* scikit-learn으로 tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### vector space model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"https://media.licdn.com/mpr/mpr/shrinknp_400_400/AAEAAQAAAAAAAAEDAAAAJGJlMzAwMzU0LTQ5MTEtNDk4Yi04MDVlLWMzN2MwMzZiNzQxMw.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### BOW (Bag of Words) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"https://image.slidesharecdn.com/mrkt451speciallecture1i-140307202701-phpapp01/95/introduction-to-text-mining-8-638.jpg?cb=1394224092\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"http://images.slideplayer.com/16/5094063/slides/slide_2.jpg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"http://www.bloter.net/wp-content/uploads/2016/09/td-idf-graphic-765x255.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"https://i.ytimg.com/vi/zvFGNpbAfEI/hqdefault.jpg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## gensim으로 tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "gensim에서 tf-idf을 계산하려면 문서 목록인 documents를 corpus 클래스로 바꿔야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 가상의 4가지 문서 \n",
    "documents = [\n",
    "    \"a b c a\",\n",
    "    \"c b c\",\n",
    "    \"b b a\",\n",
    "    \"a c c\",\n",
    "    \"c b a\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# 단어(토큰) 단위로 분할\n",
    "texts = list(map(lambda x: x.split(), documents))\n",
    "\n",
    "pprint(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "# Dictionary 객체. 구체적으로는 단어에 id 할당 (그 외에도 여러가지 기능은 튜토리얼 참조)\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "pprint(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 위의 dictioanry를 사용하여 방금 전의 texts를 corpus로 바꾼다.\n",
    "# 각 문서의 (출현 단어 id, 출현 횟수) 튜플의 리스트 \n",
    "corpus = list(map(dictionary.doc2bow, texts))\n",
    "pprint(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# corpus에서 tfidf 모델 생성\n",
    "from gensim import models\n",
    "tfidf_model = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 코퍼스들의 tf-idf 구함\n",
    "corpus_tfidf = tfidf_model[corpus]\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# tf-idf기반 유사 문서 찾기\n",
    "from gensim import similarities\n",
    "sims = similarities.Similarity('./',corpus_tfidf,\n",
    "                                      num_features=len(dictionary))\n",
    "print(sims)\n",
    "print(type(sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 비교할 문서도 tf-idf로 변경해줘야 한다.\n",
    "pprint(texts)\n",
    "\n",
    "query_doc = ['c', 'c', 'c']\n",
    "print(query_doc)\n",
    "query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "print(query_doc_bow)\n",
    "query_doc_tf_idf = tfidf_model[query_doc_bow]\n",
    "print(query_doc_tf_idf)\n",
    "\n",
    "sims[query_doc_tf_idf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 실습 1 \n",
    "#### 1) 이걸 tf-idf 벡터화 해보자.\n",
    "```python\n",
    "raw_documents = [\"I'm taking the show on the road.\",\n",
    "                 \"My socks are a force multiplier.\",\n",
    "                 \"I am the barber who cuts everyone's hair who doesn't cut their own.\",\n",
    "                 \"Legend has it that the mind is a mad monkey.\",\n",
    "                 \"I make my own fun.\"]\n",
    "```                 \n",
    "#### 2) 위의 문서 중에서 아래 문서와 가장 유사한 것은 무엇인가?\n",
    "```python\n",
    "query_doc = \"Socks are a force for good.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 실습 2\n",
    "#### 1) 다음 문서들을 tf-idf 벡터로 만들어보자.\n",
    "* https://gasazip.com/view.html?no=614736\n",
    "* https://gasazip.com/1224697\n",
    "* https://gasazip.com/view.html?no=599082\n",
    "* https://gasazip.com/view.html?no=645465\n",
    "* http://gasazip.com/view.html?no=643505\n",
    "* https://gasazip.com/view.html?no=615362\n",
    "\n",
    "#### 2) 위의 문서 중에서 아래 문서와 가장 유사한 것은 무엇인가?\n",
    "* https://gasazip.com/view.html?no=636135"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## scikit-learn으로 tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Scikit-Learn 의 feature_extraction 서브패키지와 feature_extraction.text 서브 패키지는 다음과 같은 문서 전처리용 클래스를 제공.\n",
    "\n",
    "* DictVectorizer:\n",
    "    - 단어의 수를 세어놓은 사전에서 BOW 벡터를 만든다.\n",
    "* CountVectorizer:\n",
    "    - 문서 집합으로부터 단어의 수를 세어 BOW 벡터를 만든다.\n",
    "* TfidfVectorizer:\n",
    "    - 문서 집합으로부터 단어의 수를 세고 TF-IDF 방식으로 단어의 가중치를 조정한 BOW 벡터를 만든다.\n",
    "* HashingVectorizer:\n",
    "    - hashing trick 을 사용하여 빠르게 BOW 벡터를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 코퍼스에서 빈도 벡터 만들기\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "    'The last document?',    \n",
    "]\n",
    "vect = CountVectorizer()\n",
    "vect.fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vect.transform(['This is the second document.']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vect.transform(['Something completely new.']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vect.transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stop Words (사전 생성할 때 무시할 단어들) 적용\n",
    "vect = CountVectorizer(stop_words=[\"and\", \"is\", \"the\", \"this\"]).fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words=\"english\").fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 웹 문서 빈도 분석\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import string\n",
    "from konlpy.utils import pprint\n",
    "from konlpy.tag import Hannanum\n",
    "hannanum = Hannanum()\n",
    "\n",
    "url = \"https://gasazip.com/view.html?no=614736\"\n",
    "#url = \"https://gasazip.com/view.html?no=636135\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# HTTP GET Request\n",
    "req = requests.get(url)\n",
    "# HTML 소스 가져오기\n",
    "html = req.text\n",
    "# BeautifulSoup으로 html소스를 python객체로 변환하기\n",
    "# 첫 인자는 html소스코드, 두 번째 인자는 어떤 parser를 이용할지 명시.\n",
    "# 이 글에서는 Python 내장 html.parser를 이용했다.\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lyrics = []\n",
    "for txt in soup.find_all('div', attrs={'class': 'col-md-8'}) :\n",
    "    lines = txt.get_text().split('\\n')\n",
    "    for line in lines :\n",
    "        lyrics.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "docs = [w for w in hannanum.nouns(\" \".join(lyrics)) if ((not w[0].isnumeric()) and (w[0] not in string.punctuation))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "여기에서는 하나의 문서가 하나의 단어로만 이루어져 있다. 따라서 CountVectorizer로 이 문서 집합을 처리하면 각 문서는 하나의 원소만 1이고 나머지 원소는 0인 벡터가 된다. 이 벡터의 합으로 빈도를 알아보았다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vect = CountVectorizer().fit(docs)\n",
    "count = vect.transform(docs).toarray().sum(axis=0)\n",
    "idx = np.argsort(-count)\n",
    "count = count[idx]\n",
    "feature_name = np.array(vect.get_feature_names())[idx]\n",
    "plt.bar(range(len(count)), count)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pprint(list(zip(feature_name, count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 코퍼스에서 tf-idf 벡터 만들기\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "    'The last document?',    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tfidv = TfidfVectorizer().fit(corpus)\n",
    "corpus_tfidf = tfidv.transform(corpus).toarray()\n",
    "corpus_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(corpus_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 실습 3 - 실습 2를 scikit-learn으로 해보자\n",
    "#### 1) 다음 문서들을 tf-idf 벡터로 만들어보자.\n",
    "* https://gasazip.com/view.html?no=614736\n",
    "* https://gasazip.com/1224697\n",
    "* https://gasazip.com/view.html?no=599082\n",
    "* https://gasazip.com/view.html?no=645465\n",
    "* http://gasazip.com/view.html?no=643505\n",
    "* https://gasazip.com/view.html?no=615362\n",
    "\n",
    "#### 2) 위의 문서 중에서 아래 문서와 가장 유사한 것은 무엇인가?\n",
    "* https://gasazip.com/view.html?no=636135"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Distributional word representations\n",
    "* 환경 설정\n",
    "* Distributional matrices\n",
    "* Vector comparison\n",
    "* Distributional neighbors\n",
    "* Matrix reweighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 참고\n",
    "* [7] CS224U: Natural Language Understanding - https://web.stanford.edu/class/cs224u/\n",
    "* [8] CS224U: Natural Language Understanding / Distributional word representations \n",
    "    - notebook -  http://nbviewer.jupyter.org/github/cgpotts/cs224u/blob/master/vsm.ipynb\n",
    "    - Overview slide - https://web.stanford.edu/class/cs224u/materials/cs224u-vsm-overview.pdf\n",
    "    - Vector comparison slide - https://web.stanford.edu/class/cs224u/materials/cs224u-vsm-veccompare.pdf\n",
    "    - Reweighting slide - https://web.stanford.edu/class/cs224u/materials/cs224u-vsm-weighting.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 환경 설정\n",
    "* data - https://web.stanford.edu/class/cs224u/data/vsmdata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!wget https://web.stanford.edu/class/cs224u/data/vsmdata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!unzip vsmdata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!ls vsmdata*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vsmdata_home = \"vsmdata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import random\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.spatial.distance\n",
    "from numpy.linalg import svd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Distributional matrices\n",
    "* Overview slide - https://web.stanford.edu/class/cs224u/materials/cs224u-vsm-overview.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The data distribution includes two pre-computed matrices of co-occurrence counts in IMDB movie reviews. The build function in the utils module for this repository allows you to read them in:\n",
    "\n",
    "Let's read these in now for use in later examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ww = utils.build(os.path.join(vsmdata_home, 'imdb-wordword.csv'))\n",
    "wd = utils.build(os.path.join(vsmdata_home, 'imdb-worddoc.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(len(ww))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(len(ww[0]), ww[0][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(len(ww[1]), ww[1][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(len(ww[2]), ww[2][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Vector comparison\n",
    "* Vector comparison slide - https://web.stanford.edu/class/cs224u/materials/cs224u-vsm-veccompare.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Euclidean distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"https://render.githubusercontent.com/render/math?math=%5Csqrt%7B%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%20%7Cu_%7Bi%7D-v_%7Bi%7D%7C%5E2%7D&mode=display\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def euclidean(u, v):    \n",
    "    \"\"\"Eculidean distance between 1d np.arrays `u` and `v`, which must \n",
    "    have the same dimensionality. Returns a float.\"\"\"\n",
    "    # Use scipy's method:\n",
    "    return scipy.spatial.distance.euclidean(u, v)\n",
    "    # Or define it yourself:\n",
    "    # return vector_length(u - v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### vector length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"https://render.githubusercontent.com/render/math?math=%5C%7Cu%5C%7C%20%3D%20%5Csqrt%7B%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%20u_%7Bi%7D%5E%7B2%7D%7D&mode=display\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def vector_length(u):\n",
    "    \"\"\"Length (L2) of the 1d np.array `u`. Returns a new np.array with the \n",
    "    same dimensions as `u`.\"\"\"\n",
    "    return np.sqrt(np.dot(u, u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ABC = np.array([\n",
    "    [ 2.0,  4.0],  # A\n",
    "    [10.0, 15.0],  # B\n",
    "    [14.0, 10.0]]) # C\n",
    "\n",
    "def plot_ABC(m):\n",
    "    plt.plot(m[:,0], m[:,1], marker='', linestyle='')\n",
    "    plt.xlim([0,np.max(m)*1.2])\n",
    "    plt.ylim([0,np.max(m)*1.2])\n",
    "    for i, x in enumerate(['A','B','C']):\n",
    "        plt.annotate(x, m[i,:])\n",
    "\n",
    "plot_ABC(ABC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "euclidean(ABC[0], ABC[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "euclidean(ABC[1], ABC[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Length normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def length_norm(u):\n",
    "    \"\"\"L2 norm of the 1d np.array `u`. Returns a float.\"\"\"\n",
    "    return u / vector_length(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_ABC(np.array([length_norm(row) for row in ABC]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Cosine distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"https://render.githubusercontent.com/render/math?math=1%20-%20%5Cleft%28%5Cfrac%7B%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%20u_%7Bi%7D%20%5Ccdot%20v_%7Bi%7D%7D%7B%5C%7Cu%5C%7C%5Ccdot%20%5C%7Cv%5C%7C%7D%5Cright%29&mode=display\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cosine(u, v):        \n",
    "    \"\"\"Cosine distance between 1d np.arrays `u` and `v`, which must have \n",
    "    the same dimensionality. Returns a float.\"\"\"\n",
    "    # Use scipy's method:\n",
    "    return scipy.spatial.distance.cosine(u, v)\n",
    "    # Or define it yourself:\n",
    "    # return 1.0 - (np.dot(u, v) / (vector_length(u) * vector_length(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for m in (euclidean, cosine):\n",
    "    fmt = {'n': m.__name__,  \n",
    "           'AB': m(ABC[0], ABC[1]), \n",
    "           'BC': m(ABC[1], ABC[2])}\n",
    "    print('%(n)15s(A, B) = %(AB)5.2f %(n)15s(B, C) = %(BC)5.2f' % fmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Distributional neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def neighbors(word, mat, rownames, distfunc=cosine):    \n",
    "    \"\"\"Tool for finding the nearest neighbors of `word` in `mat` according \n",
    "    to `distfunc`. The comparisons are between row vectors.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word : str\n",
    "        The anchor word. Assumed to be in `rownames`.\n",
    "        \n",
    "    mat : np.array\n",
    "        The vector-space model.\n",
    "        \n",
    "    rownames : list of str\n",
    "        The rownames of mat.\n",
    "            \n",
    "    distfunc : function mapping vector pairs to floats (default: `cosine`)\n",
    "        The measure of distance between vectors. Can also be `euclidean`, \n",
    "        `matching`, `jaccard`, as well as any other distance measure  \n",
    "        between 1d vectors.\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If word is not in rownames.\n",
    "    \n",
    "    Returns\n",
    "    -------    \n",
    "    list of tuples\n",
    "        The list is ordered by closeness to `word`. Each member is a pair \n",
    "        (word, distance) where word is a str and distance is a float.\n",
    "    \n",
    "    \"\"\"\n",
    "    if word not in rownames:\n",
    "        raise ValueError('%s is not in this VSM' % word)\n",
    "    w = mat[rownames.index(word)]\n",
    "    dists = [(rownames[i], distfunc(w, mat[i])) for i in range(len(mat))]\n",
    "    return sorted(dists, key=itemgetter(1), reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "neighbors(word='superb', mat=ww[0], rownames=ww[1], distfunc=cosine)[: 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "neighbors(word='superb', mat=ww[0], rownames=ww[1], distfunc=euclidean)[: 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Matrix reweighting\n",
    "* Reweighting slide - https://web.stanford.edu/class/cs224u/materials/cs224u-vsm-weighting.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def prob_norm(u):\n",
    "    \"\"\"Normalize 1d np.array `u` into a probability distribution. Assumes \n",
    "    that all the members of `u` are positive. Returns a 1d np.array of \n",
    "    the same dimensionality as `u`.\"\"\"\n",
    "    return u / np.sum(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tfidf(mat, rownames=None):\n",
    "    \"\"\"TF-IDF \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mat : 2d np.array\n",
    "       The matrix to operate on.\n",
    "       \n",
    "    rownames : list of str or None\n",
    "        Not used; it's an argument only for consistency with other methods \n",
    "        defined here.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    (np.array, list of str)    \n",
    "       The first member is the TF-IDF-transformed version of `mat`, and \n",
    "       the second member is `rownames` (unchanged).\n",
    "    \n",
    "    \"\"\"\n",
    "    colsums = np.sum(mat, axis=0)\n",
    "    doccount = mat.shape[1]\n",
    "    w = np.array([_tfidf_row_func(row, colsums, doccount) for row in mat])\n",
    "    return (w, rownames)\n",
    "\n",
    "def _tfidf_row_func(row, colsums, doccount):\n",
    "    df = float(len([x for x in row if x > 0]))\n",
    "    idf = 0.0\n",
    "    # This ensures a defined IDF value >= 0.0:\n",
    "    if df > 0.0 and df != doccount:\n",
    "        idf = np.log(doccount / df)\n",
    "    tfs = row/colsums\n",
    "    return tfs * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wd_tfidf = tfidf(mat=wd[0], rownames=wd[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "neighbors(word='superb', mat=wd_tfidf[0], rownames=wd_tfidf[1], distfunc=cosine)[: 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 참고자료\n",
    "* [1] gensim の tfidf で正規化（normalize）に苦しんだ話 - http://tawara.hatenablog.com/entry/2016/11/08/021408\n",
    "* [2] How do I compare document similarity using Python? - https://www.oreilly.com/learning/how-do-i-compare-document-similarity-using-python\n",
    "* [3] Scikit-Learn의 문서 전처리 기능 - https://datascienceschool.net/view-notebook/3e7aadbf88ed4f0d87a76f9ddc925d69/\n",
    "* [4] 나만의 웹 크롤러 만들기 with Requests/BeautifulSoup - https://beomi.github.io/2017/01/20/HowToMakeWebCrawler/\n",
    "* [5] scikit-learn: TF/IDF and cosine similarity for computer science papers - http://www.markhneedham.com/blog/2016/07/27/scitkit-learn-tfidf-and-cosine-similarity-for-computer-science-papers/\n",
    "* [6] sklearn.metrics.pairwise.cosine_similarity - http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html#sklearn.metrics.pairwise.cosine_similarity\n",
    "* [7] CS224U: Natural Language Understanding - https://web.stanford.edu/class/cs224u/\n",
    "* [8] CS224U: Natural Language Understanding / Distributional word representations \n",
    "    - notebook -  http://nbviewer.jupyter.org/github/cgpotts/cs224u/blob/master/vsm.ipynb\n",
    "    - Overview slide - https://web.stanford.edu/class/cs224u/materials/cs224u-vsm-overview.pdf\n",
    "    - Vector comparison slide - https://web.stanford.edu/class/cs224u/materials/cs224u-vsm-veccompare.pdf\n",
    "    - Reweighting slide - https://web.stanford.edu/class/cs224u/materials/cs224u-vsm-weighting.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
